# Брокеры сообщений

## 1. Общие сведения о брокерах сообщений

### 1.1 Что такое брокер сообщений?

**Брокер сообщений** (Message Broker) — это компонент, который организует обмен сообщениями (данными) между различными частями (сервисами, микросервисами, приложениями) в асинхронном режиме. Основная идея — предоставить надёжную и масштабируемую систему коммуникаций:

1. Клиент (Publisher/Producer) отправляет сообщение в брокер.
2. Брокер сохраняет сообщение и доставляет его одному или нескольким подписчикам (Consumers).

### 1.2 Зачем нужны брокеры сообщений?

- **Асинхронность**: отправитель не ждёт, пока получатель прочитает сообщение; повышается отзывчивость системы.
- **Слабая связь** систем. Отправителю не интересно куда он посылает сообщение, получатель не знает про отправителей.
- **Можно использовать как потоковую систему обработки данных**. Обрабатывать возникающие события сразу, а не пакетами, когда, например сработает крон.
- **Буферизация**: брокер хранит сообщения, пока получатель не сможет их обработать. Если получатель упал до взятия сообщения, или упал в процессе обработки сообщения, то сообщение останется доступным. **В кафке сообщения не удаляются.** 
- **Устойчивость к сбоям**: большинство брокеров позволяют настраивать репликацию, чтобы избежать потери данных.
- **Гибкость**: легко подключать новых подписчиков, менять маршруты сообщений, не нарушая логику существующей системы.

### 1.3 Примеры брокеров

- **RabbitMQ**
- **Apache Kafka**
- **ActiveMQ**
- **Amazon SQS**
- **Google Pub/Sub**
- **Azure Service Bus**

---

## 2. Особенности Apache Kafka

**Apache Kafka** — это платформа потоковой передачи (streaming platform), которая сочетает функции брокера сообщений и системы для обработки больших потоков данных в реальном времени.

### 2.1 Ключевые концепции Kafka

1. **Topic (Топик)** — логическая категория сообщений.
2. **Partition (Партиция)** — логическое разделение внутри топика; каждый топик разбит на несколько партиций для параллелизма и масштабируемости. Причем партиции топика могут лежать в разных брокерах. Используют реплики для партиций внутри разных брокеров. Брокер, где лежит оригинальная партиция - называется лидером. Чтение из реплик не происходит, они просто догоняют лидера, только если лидер упал, то чтение пойдет через реплики. 
3. **Broker (Брокер)** — сервер Kafka, хранящий партиции. В кластере может быть несколько брокеров. Обычно кафка поднимается сразу с несколькими брокерами.
4. **Producer (Продюсер)** — процесс, который записывает сообщения (events) в конкретные топики.
5. **Consumer (Потребитель)** — процесс, который читает сообщения из топиков. Часто объединяется в **Consumer Group**.
6. **Offset (Смещение)** — уникальный идентификатор сообщения в рамках партиции. Каждый ConsumerGroup отслеживает, на каком offset находится.

### 2.2 Отличительные черты Kafka

- **Высокая пропускная способность** и масштабируемость: топик может иметь много партиций, брокеров в кластере.
- **Хранение сообщений на диске** (как лог), что позволяет «перечитывать» историю сообщений. Сообщение не удаляется.
- **Consumer Groups**: каждый Consumer в группе читает свою часть партиций (распределённое чтение).
- **Подход «pull»**: потребители сами запрашивают сообщения (pull), в отличие от некоторых других систем, где брокер «пушит» (push) сообщения.
- **Подходит не только для очередей**, но и для потоковой аналитики (stream processing).
- Горизонтальное масштабирование.

### 2.3 Использование Kafka

- **Событийная архитектура**: хранение и доставка бизнес-событий (Event Sourcing).
- **Логи**: сбор лог-сообщений со множества источников и дальнейшая обработка.
- **Интеграция систем**: через общий шина данных (data bus).
- **Real-time Analytics**: обработка потока в режиме реального времени (с помощью Apache Spark, Apache Flink и т.д.).

---

## 3. Сравнение Apache Kafka и RabbitMQ

Хотя оба являются брокерами сообщений, они исходно разрабатывались под разные задачи.

| Характеристика             | **Apache Kafka**                                                                                          | **RabbitMQ**                                                         |
| -------------------------- | --------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| **Модель**                 | Лог (publish-subscribe). Consumer сам читает «лог»                                                        | Классическая очередь (push or pull)                                  |
| **Подход к хранению**      | Сообщения хранятся на дисках кластера; «лог» может перечитываться                                         | Сообщения обычно удаляются после чтения                              |
| **Скорость / Производит.** | Очень высокая, особенно при больших объёмах данных                                                        | Высокая, но ориентирована на классические очереди                    |
| **Использование**          | Потоковая аналитика, event sourcing, сбор данных из многих источников                                     | Асинхронное взаимодействие микросервисов, RPC, стандартное pub/sub   |
| **Масштабирование**        | Масштабирование по партициям топиков и репликация брокеров                                                | Горизонтальное масштабирование кластером (но модель партиций другая) |
| **Delivery Guarantees**    | At-least-once (по умолчанию), возможны Exactly-once / At-most-once при особых настройках                  | At-least-once, поддержка подтверждений (ACK/NACK)                    |
| **Сложность**              | Более «тяжёлая» инфраструктура (ZooKeeper/кворм, хотя с новыми версиями Kafka есть KIP-500 для упрощения) | Проще в установке и эксплуатации (часто)                             |

---

## 4. Подходы к тестированию (QA) при использовании брокеров сообщений

### 4.1 Общие моменты

1. **Функциональное тестирование**: проверить, правильно ли публикуются и обрабатываются сообщения, приходят ли ответы туда, куда нужно.
2. **Интеграционное тестирование**: при взаимодействии нескольких сервисов через брокер нужно проверять корректность формата сообщений, обработку ошибок, ретраи (retries) и таймауты.
3. **Performance / Нагрузочное тестирование**: проверять throughput (пропускную способность), задержки, сколько сообщений могут обрабатываться одновременно.
4. **Failover-тестирование**: брокер может «упасть» или отключиться сеть — надо проверять, что система восстанавливается без потери данных или с минимальными последствиями.
5. **Security-тестирование**: проверять права доступа, TLS/SSL-соединения, аутентификацию (SASL), чтобы никто не мог читать или писать в топики/очереди без разрешения.

### 4.2 Тестирование специфики Kafka

1. **Проверка партиций**: правильно ли распределяются сообщения по партициям.
2. **Коммит offset**: работает ли корректный учёт, на каком offset остановились потребители.
3. **Ретеншн (Retention)**: если сообщения должны храниться, проверять, что они не удаляются раньше времени.
4. **Ре-плей** сообщений**: важная фича Kafka — возможность перечитывать лог. Проверить, что при изменении ConsumerGroup или сбросе offset потребитель действительно может заново прочитать историю.

### 4.3 Тестирование специфики RabbitMQ

1. **Настройка очередей и exchange**: прямой (direct), топиковый (topic), фан-аут (fanout), пр. Проверить, что маршрутизация работает.
2. **Подтверждения (ACK/NACK)**: потребитель должен подтверждать успешную обработку, чтобы сообщение удалилось из очереди.
3. **Персистентность (durable)**: очередь и сообщения могут быть «персистентными», значит, они сохраняются при перезагрузке брокера.
4. **Dead Letter Exchanges**: проверить поведение, когда сообщение не может быть доставлено (DLX).

---

## 5. Вопросы и ответы для собеседования

Ниже список наиболее частых вопросов по брокерам сообщений, а также примерные ответы, демонстрирующие понимание специфики, в т. ч. Kafka.

### Вопрос 1. Зачем использовать брокер сообщений?

**Пример ответа**:

«Брокер сообщений нужен для асинхронного взаимодействия: позволяет отправлять и получать данные между сервисами, не блокируя друг друга, а также гибко масштабировать систему. Это повышает надёжность и снижает связность (coupling) между компонентами.»

### Вопрос 2. В чём отличие Apache Kafka от RabbitMQ?

**Пример ответа**:

«Kafka основан на модели «логов» (publish-subscribe) и хранит сообщения на дисках, позволяя перечитывать историю. RabbitMQ — классическая очередь, где сообщения удаляются после обработки. Kafka идеально подходит для потоковых данных и аналитики, а RabbitMQ — для надёжных очередей в микросервисной архитектуре (RPC, запрос-ответ и т.д.).»

### Вопрос 3. Как вы тестировали бы систему, где используется Kafka?

**Пример ответа**:

1. «Проверил бы корректное создание топиков и партиций, их репликацию.
2. Запустил бы функциональные тесты, чтобы убедиться, что нужные сообщения публикуются и потребляются.
3. Провёл бы нагрузочное тестирование, чтобы оценить throughput и задержки при увеличении числа сообщений.
4. Смоделировал бы сбой брокера (или выключил один узел в кластере), чтобы проверить механизм failover и репликации.»

### Вопрос 4. Что такое Consumer Group в Kafka и почему это важно?

**Пример ответа**:

«Consumer Group — это набор потребителей, которые совместно читают сообщения из топика. Каждая партиция топика может назначаться только одному потребителю группы, что позволяет параллелить чтение. Важно для масштабирования системы потребления: мы можем добавить больше потребителей в группу и обрабатывать сообщения быстрее.»

### Вопрос 5. Какие гарантии доставки сообщений (delivery guarantees) поддерживает Kafka?

**Пример ответа**:

«По умолчанию у Kafka — At-least-once (каждое сообщение доставляется как минимум один раз). При определённых настройках продюсеров и потребителей можно достичь Exactly-once (особенно при использовании транзакций) или At-most-once. Но для «из коробки» At-least-once является базовой гарантией.»

### Вопрос 6. Расскажите о ретеншне (Retention) в Kafka.

**Пример ответа**:

«Retention — это срок (или размер), в течение которого сообщения хранятся в топике на диске. По истечении времени или при превышении объёма старые сообщения могут удаляться. Kafka заточена на идею, что мы можем хранить и перечитывать большой поток данных за период, поэтому ретеншн — ключевой параметр конфигурации.»

### Вопрос 7. Как обеспечить сохранность (durability) сообщений при сбоях брокера?

**Пример ответа**:

«В Kafka можно настроить репликацию топиков (replication factor > 1). Продюсер может ждать подтверждений от всех реплик (acks=all). В RabbitMQ есть параметр «durable» для очередей и «persistent» для сообщений. В обоих случаях это минимизирует риск потери данных при сбоях.»

### Вопрос 8. Что такое ACK/NACK в контексте RabbitMQ и почему это важно?

**Пример ответа**:

«ACK (подтверждение) означает, что потребитель успешно обработал сообщение, и брокер может удалить его из очереди. Если потребитель отправляет NACK (отказ), брокер решает, что делать с сообщением (перенаправлять ли его снова, отправлять в DLX и т.д.). Это гарантирует корректность доставки и позволяет реагировать на ошибки при обработке.»

### Вопрос 9. В чём особенности тестирования производительности (Perf Testing) брокеров?

**Пример ответа**:

«Нужно проверять пропускную способность (msgs/second), среднюю и максимальную задержку (latency). Важно моделировать реальную нагрузку: количество продюсеров и потребителей, размер сообщений, сценарии скачкообразной нагрузки. Также надо следить за ресурсами (CPU, RAM, disk I/O) на брокерах и в сети.»

### Вопрос 10. Как тестировщик может локально воспроизводить сценарии с Kafka/RabbitMQ?

**Пример ответа**:

«Можно использовать Docker-Compose, чтобы поднять контейнер с Kafka (включая ZooKeeper) или RabbitMQ. Затем локально запустить тесты, публикуя сообщения в брокер и проверяя, как они доставляются. Так легче воспроизвести ошибки, посмотреть логи, провести интеграционные сценарии перед тем, как идти на реальный стенд.»

---

## 6. Дополнительные советы для тестировщика

1. **Разобраться в CLI**: у Kafka есть консольные утилиты (kafka-console-producer, kafka-console-consumer) для быстрой отладки, у RabbitMQ — `rabbitmqctl` и панель управления.
2. **Логирование и метрики**: при больших нагрузках пользоваться мониторингом (Prometheus + Grafana, ELK-стек), чтобы увидеть, где возникает узкое место.
3. **Понимать формат сообщений**: JSON, Avro, Protobuf. Убедиться, что схема совместима, особенно в микросервисах (использовать схемы, versioning).
4. **Проверять настройки**: Retention, replication, acks, durable/HA queue, auto-delete, TTL (time-to-live). От них зависит поведение и надёжность.