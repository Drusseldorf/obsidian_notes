## 1. Введение: Конкурентность и параллелизм

- **Основные понятия:**
    - **Конкурентность (Concurrency)** – умение управлять множеством задач одновременно, позволяющее структурировать решение проблемы (не обязательно выполняющееся параллельно).
    - **Параллелизм (Parallelism)** – одновременное выполнение множества вычислений, требующее наличия нескольких ядер или процессоров.
- **Цитата Роберта Пайка:**
    
    > «Concurrency – это способ структурировать решение, а параллелизм – способ выполнения задач одновременно».
    
- **Задача главы:**  
    Рассмотрение возможностей Python по выполнению множества задач «одновременно» с использованием потоков (threads), процессов (multiprocessing) и асинхронных корутин (asyncio).

---

## 2. Основной словарь терминов

Автор вводит следующие понятия, необходимые для понимания конкуренции в Python:

- **Execution Unit (Единица выполнения):**  
    Объект, исполняющий код независимо. В Python – процессы, потоки и корутины.
- **Процесс (Process):**
    - Независимый экземпляр программы, использующий выделенную память.
    - Обменивается данными через сериализацию (пайп, сокеты, mmap).
    - Обеспечивает предопределённое планирование ОС (preemptive multitasking).
- **Поток (Thread):**
    - Единица выполнения внутри процесса.
    - Потоки разделяют память, что упрощает обмен данными, но требует синхронизации (например, с помощью блокировок).
    - Планирование происходит ОС, но расходует меньше ресурсов, чем процесс.
- **Корутина (Coroutine):**
    - Функция, которая может приостанавливать своё выполнение (yield/await) и возобновляться.
    - Работают внутри одного потока (однопоточное выполнение) под управлением event loop.
    - Позволяют реализовать кооперативную многозадачность.
- **Очередь (Queue):**  
    Структура для обмена данными между единицами выполнения, реализуемая по-разному в модулях `queue`, `multiprocessing` и `asyncio`.
- **Блокировка (Lock):**  
    Механизм синхронизации для предотвращения одновременного доступа к общим данным.
- **Конкуренция за ресурс (Contention):**  
    Ситуация, когда несколько единиц выполнения пытаются одновременно получить доступ к ограниченным ресурсам.

---

## 3. Особенности реализации конкуренции в Python и роль GIL

- **Процессы и потоки в Python:**
    - Каждый запуск интерпретатора – это отдельный процесс.
    - Стандартный интерпретатор (CPython) использует один основной поток для выполнения пользовательского кода, а дополнительные потоки можно запускать через модули `threading` или `concurrent.futures`.
- **Global Interpreter Lock (GIL):**
    - GIL – это блокировка, которая позволяет одновременно выполняться только одному потоку Python-кода.
    - GIL периодически освобождается (по умолчанию каждые 5 мс), что позволяет другим потокам получать доступ, но не устраняет проблемы при вычислительно интенсивных задачах.
    - **Важное замечание:**  
        Для CPU-интенсивных задач, использующих Python-код, использование потоков может даже ухудшать производительность. Для распараллеливания таких вычислений рекомендуется использовать процессы.
- **Освобождение GIL:**
    - Многие стандартные функции, выполняющие системные вызовы (I/O, `time.sleep()`), освобождают GIL.
    - Расширения на C могут вручную освобождать GIL при выполнении тяжёлых вычислений.

---

## 4. Пример: Concurrent Hello World

Автор иллюстрирует применение трёх моделей конкуренции с помощью «вращающегося спиннера», который сообщает пользователю, что программа «думает», пока выполняется тяжёлая задача (например, задержка в 3 секунды или проверка числа на простоту).

### 4.1. Спиннер с использованием потоков

- **Идея:**  
    Запустить функцию `spin` в отдельном потоке, которая циклически выводит символы из строки `r'\|/-'` с обновлением строки в терминале. Главный поток выполняет функцию `slow`, которая имитирует долгую операцию (например, `time.sleep(3)`).
    
- **Ключевые моменты:**
    
    - Используется `threading.Event` для сигнала остановки спиннера.
    - Поток спиннера обновляет экран каждые 0.1 с (10 FPS).
    - После завершения `slow` главный поток выставляет флаг события, и поток спиннера завершает выполнение.
### 4.2. Спиннер с использованием процессов

- **Идея:**  
    Почти идентична потоковой реализации, но запускается новый процесс через модуль `multiprocessing`.
- **Особенности:**
    - API процесса очень похож на API потока, но требуется учитывать особенности сериализации (например, объекты очереди и Event).
    - Каждый процесс имеет свой GIL, что позволяет использовать многопроцессорность для CPU-интенсивных задач.
- **Пример кода:**  
    Основные изменения – импорт из `multiprocessing` и использование `multiprocessing.Event`.

### 4.3. Спиннер с использованием асинхронных корутин (asyncio)

- **Идея:**  
    Запустить асинхронную функцию `spin` как задачу (Task) в event loop, а функция `slow` выполняется как корутина с помощью `await asyncio.sleep(3)`.
    
- **Ключевые моменты:**
    
    - Корутинная версия позволяет легко отменить задачу через метод `Task.cancel()`.
    - **Важное предупреждение:**  
        Никогда не использовать `time.sleep()` в корутинах, так как это блокирует event loop и останавливает выполнение всех задач. Вместо этого — `await asyncio.sleep()`.`

---

## 5. Сравнение моделей конкуренции и особенности отмены задач

- **Thread vs. Process vs. Coroutine:**
    
    - **Потоки:**
        - Запускаются через вызов `start()`; не существует API для «вынужденного» завершения потока – используется событие для сигнала.
        - Подвержены влиянию GIL, но для задач, связанных с I/O, это не критично.
    - **Процессы:**
        - Полностью изолированы; каждый процесс имеет собственный GIL, что позволяет задействовать все ядра ЦП.
        - Межпроцессное взаимодействие требует сериализации (pickle), что создаёт накладные расходы.
    - **Асинхронные корутины:**
        - Выполняются в одном потоке под управлением event loop.
        - Отмена задачи происходит посредством `Task.cancel()`, что вызывает исключение `asyncio.CancelledError` в месте await.
        - Не подходят для CPU-интенсивных задач – блокируют event loop, если использовать синхронные вызовы (например, `time.sleep()` вместо `await asyncio.sleep()`).
- **Сравнение функций-надзирателей (supervisor):**
    
    - В версии с потоками используется `Event` для завершения задачи.
    - В асинхронном варианте используется создание задачи (`asyncio.create_task`) и последующая отмена через `cancel()`.
- **Замечание автора:**  
    При использовании асинхронного подхода важно правильно использовать `await asyncio.sleep(...)` для уступания управления, иначе асинхронный код может заблокировать выполнение всей программы.
    

---

## 6. Проблемы с CPU-интенсивными вычислениями и влияние GIL

- **Эксперимент с вычислением простоты числа:**
    
    - Функция `is_prime(n)` используется для проверки, является ли число простым.
    - Замена `time.sleep(3)` на вызов `is_prime(большое_число)` показывает, как различные модели конкуренции реагируют на CPU-интенсивные задачи:
        1. **Многопроцессный вариант:**
            - Спиннер продолжает работать, так как основной процесс вычисляет, а анимация – в другом процессе.
        2. **Потоковый вариант:**
            - Несмотря на GIL, спиннер продолжает анимацию, так как основной поток периодически уступает управление (каждые 5 мс по умолчанию).
            - Однако при увеличении числа потоков производительность падает из-за накладных расходов на переключение контекста и конкуренции за GIL.
        3. **Асинхронный вариант:**
            - Если заменить `await asyncio.sleep(3)` на вызов `is_prime(большое_число)`, то спиннер не появляется, поскольку вызов блокирует event loop.
- **Рекомендация:**  
    Для CPU-интенсивных задач в асинхронном коде следует либо периодически вызывать `await asyncio.sleep(0)` (чтобы дать возможность event loop переключаться), либо передавать вычисления в отдельный процесс (например, с помощью `run_in_executor`).
    
- **Пример корректировки для корутин (power napping):**
    
    **Предупреждение:** Использование `await asyncio.sleep(0)` замедляет вычисление и не является оптимальным решением для тяжёлых вычислений.
    

---

## 7. Домашний процессный пул (Homegrown Process Pool)

- **Цель раздела:**  
    Показать, как распределять CPU-интенсивные задачи (например, проверку простоты чисел) между несколькими процессами с использованием очередей.
    
- **Подход:**
    
    - **Очереди:**  
        Используются две очереди:
        - **JobQueue** – для передачи заданий (чисел для проверки).
        - **ResultQueue** – для сбора результатов (кортежи с числом, результатом проверки и временем вычисления).
    - **Рабочий процесс (worker):**  
        Зацикливается, получая число из очереди, выполняет проверку и помещает результат в очередь результатов.
        - Для завершения работы используется «ядовитая пилюля» (poison pill) – специальное значение (например, 0), сигнализирующее о завершении.

- **Замечания:**
    
    - Результаты, полученные из очереди, могут приходить в произвольном порядке.
    - Для обмена данными между процессами используется сериализация (что создаёт накладные расходы).

---

## 8. Итоги и применение Python в многопроцессорном мире

### 8.1. Основные выводы по моделям конкуренции

- **Потоки (threads):**
    - Подходят для I/O-интенсивных задач, но для CPU-интенсивных вычислений их использование часто менее эффективно из-за GIL.
- **Процессы (multiprocessing):**
    - Позволяют задействовать все ядра CPU, что критически важно для вычислительно тяжёлых задач.
- **Асинхронные корутины (asyncio):**
    - Эффективны для I/O-базированных задач, позволяют масштабировать тысячи конкурентных операций, но не подходят для блокирующих, CPU-интенсивных вычислений.

### 8.2. Применение в разных областях

- **Системное администрирование:**  
    Python используется для автоматизации конфигурации серверов, сетевых устройств, благодаря высокой эффективности потоков и корутин при выполнении I/O-операций.
- **Data Science и научные вычисления:**  
    Благодаря богатой экосистеме (NumPy, SciPy, TensorFlow, PyTorch, Dask), Python успешно применяется для вычислительно тяжёлых задач, часто с реализацией критичных участков на C/C++.
- **Серверная разработка и веб:**
    - Традиционные WSGI-серверы (mod_wsgi, uWSGI, Gunicorn, NGINX Unit) управляют пулом процессов для использования всех ядер.
    - Появляется ASGI – асинхронный интерфейс для серверов, позволяющий использовать корутины (например, в aiohttp, FastAPI).
- **Распределённые очереди задач:**  
    Такие инструменты, как Celery и RQ, обеспечивают делегирование фоновых задач (например, отправка email, генерация PDF) на отдельные воркеры, позволяя масштабировать приложения горизонтально.

---

## 9. Дополнительные рекомендации и литература

Автор предлагает широкий список литературы для дальнейшего изучения:

- **Concurrency с потоками и процессами:**
    - Книги, такие как «Effective Python», «Python Essential Reference», а также документация по `multiprocessing` и `concurrent.futures`.
- **Асинхронное программирование:**
    - Книги и статьи по asyncio, например, «Using Asyncio in Python».
- **Темы, связанные с GIL:**
    - Статьи и документация по CPython C-API, объясняющие природу GIL.
- **Распределённые системы и паттерны:**
    - «Designing Data-Intensive Applications» Мартина Клеппмана, материалы по RabbitMQ, Celery и прочим системам обмена сообщениями.
- **Дополнительные инструменты:**
    - Фреймворки для параллелизации (lelo, python-parallelize), эксперименты с субинтерпретаторами (PEP 554).

---

## 10. Заключительные размышления автора

- **Ограничения vs. структурирование:**
    - Автор подчёркивает, что ограничения (например, отсутствие возможности произвольного вмешательства в потоки) облегчают отладку и понимание кода.
    - Проблемы с «threads and locks» (потоками и блокировками) сравниваются с тем, как раньше приходилось программировать на ассемблере или неструктурированном BASIC.
- **Преимущества акторной модели:**
    - Модель акторов (например, в Erlang или через библиотеки Thespian/Pykka) предлагает более безопасный подход к конкуренции – обмен сообщениями вместо разделения памяти.
- **Критика «web scale envy»:**
    - Автор предупреждает против излишнего усложнения архитектуры из-за «зависти к масштабированию», напоминая о принципе KISS.