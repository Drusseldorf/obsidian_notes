# Глава 4. Unicode-текст и байты

# Вводная по понятиям

**Unicode** — это международный стандарт, который присваивает уникальный номер (кодовую точку) каждому символу, независимо от языка, платформы или программы. Он охватывает огромное количество символов, включая буквы, цифры, символы разных алфавитов, математические и специальные знаки. Основная цель Unicode — предоставить единый и универсальный набор символов для всех языков мира.

**UTF-8** — это один из способов кодирования символов Unicode. Он использует от 1 до 4 байт для представления символов, в зависимости от их кода. UTF-8 совместим с ASCII, что делает его популярным для веб-приложений и файлов, так как ASCII символы (например, латинские буквы и цифры) занимают всего 1 байт. Символы других языков или специальных знаков могут занимать больше байтов (от 2 до 4), что позволяет эффективно хранить и передавать текст.

**URL-encoding** (или percent-encoding) — это метод кодирования символов в URL-адресах, где некоторые символы заменяются их процентным представлением (`%XX`), где `XX` — это шестнадцатеричное значение байта. Это делается для того, чтобы в URL можно было безопасно передавать данные, включая пробелы, специальные символы или не-ASCII символы, которые в обычной форме могут быть интерпретированы неправильно. Например, пробел кодируется как `%20`.

### Как это связано?

- Unicode задает уникальные коды для всех символов.
- UTF-8 кодирует эти символы в байты, которые можно передавать по сети или хранить в файлах.
- URL-encoding, в свою очередь, кодирует байты, представляющие символы, в безопасный для URL формат, используя шестнадцатеричное представление, чтобы избежать ошибок и неправильно интерпретируемых символов в адресной строке.

Таким образом, Unicode определяет символы, UTF-8 кодирует их, а URL-encoding делает их безопасными для использования в URL.

**ASCII** и **UTF-8** связаны тем, что **UTF-8** является расширением **ASCII**, и они полностью совместимы в диапазоне первых 128 символов.

### Подробно:

1. **ASCII** (American Standard Code for Information Interchange) — это старый стандарт кодировки, который использует 7 бит для представления 128 символов. Эти символы включают латинские буквы (A-Z, a-z), цифры (0-9), базовые знаки пунктуации и управляющие символы (например, табуляция, перенос строки). Все они занимают по 1 байту.
2. **UTF-8** — это кодировка, которая охватывает весь набор Unicode и использует от 1 до 4 байт для представления символов.
    - Первые 128 кодов UTF-8 совпадают с ASCII. Если символ — это один из 128 ASCII символов, UTF-8 кодирует его так же, как и ASCII (в 1 байт).
    - Если символ выходит за пределы ASCII (например, это кириллица, иероглифы или специальные знаки), то UTF-8 использует больше байтов (от 2 до 4), чтобы его закодировать.

### Связь

Поскольку ASCII — это подмножество UTF-8, любой текст, закодированный в ASCII, также является допустимым UTF-8 текстом. Это обеспечивает обратную совместимость: программы, поддерживающие UTF-8, могут обрабатывать ASCII текст без каких-либо преобразований.

# Короткий конспект по темам главы

### Определение кодировки байтов

Невозможно точно определить кодировку байтовой последовательности без явного указания. Некоторые протоколы и форматы, такие как HTTP и XML, включают в себя заголовки, указывающие кодировку. UTF-8 и UTF-16 также имеют ограничения, делающие случайное совпадение маловероятным.

### Угадать кодировку с помощью Chardet

Chardet — это библиотека Python, которая может определить одну из более чем 30 кодировок на основе эвристик и статистики.

### Маркер порядка байтов (BOM)

Некоторые кодировки, такие как UTF-16, могут добавлять BOM, чтобы указать порядок байтов в файле. Например, UTF-16LE использует последовательность байтов `\xff\xfe` для обозначения «младший байт первым».

### Работа с текстовыми файлами в Python

Python 3 упрощает работу с текстовыми файлами, автоматически преобразуя байты в строки и наоборот. Но, важно указывать кодировку явно, чтобы избежать проблем с несовпадением кодировок.

### Нормализация Unicode

Проблема сравнений Unicode связана с наличием комбинируемых символов, таких как диакритические знаки. Для решения этой проблемы можно использовать `unicodedata.normalize()`. Формы нормализации:

- **NFC** — сокращает строку.
- **NFD** — разбивает на базовые символы и комбинируемые знаки.

### Определение и сортировка текста

Для правильной сортировки текста в разных языках можно использовать библиотеку pyuca (реализация алгоритма сортировки Unicode) или PyICU для более точной локализации